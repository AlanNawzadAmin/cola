{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install the repo and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip --quiet install git+https://github.com/wilson-labs/cola.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# CoLA Library Exercise\n",
    "\n",
    "This exercise is designed to help you get familiar with the CoLA linear algebra library. \n",
    "\n",
    "## Installation\n",
    "\n",
    "Make sure you have a Python 3.10+ environment with either Jax or Pytorch installed. You can install CoLA using pip:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install git+https://github.com/wilson-labs/cola.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Alternatively, you can open the documentation in Colab and start working from there: [Quick Start](https://colab.research.google.com/github/wilson-labs/cola/blob/master/docs/notebooks/colabs/Quick_Start.ipynb)\n",
    "\n",
    "Have a read through the [documentation](https://cola.readthedocs.io/en/latest/index.html) to understand the library better.\n",
    "\n",
    "## Basic Exercises\n",
    "\n",
    "1. Create a LinearOperator using the `ops.Diagonal` and `ops.Dense` classes. Perform basic operations like addition, subtraction, and multiplication on these operators.\n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Large Scale Machine Learning with CoLA\n",
    "\n",
    "Using Jax or Pytorch, pick any 3 out of the 5:\n",
    "\n",
    "### 1. GP\n",
    "\n",
    "GP Implement Gaussian Process (GP) inference with Radial Basis Function (RBF) kernel using `inverse()` from scratch on a dataset with at least 10k observations. You are not allowed to use gpytorch. The formula for the GP posterior is:\n",
    "\n",
    "$$f_* | X, y, X_* \\sim \\mathcal{N}(\\mu_*, \\Sigma_*)$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\mu_* = K(X_*, X)[K(X, X) + \\sigma^2_n I]^{-1}y$$\n",
    "\n",
    "$$\\Sigma_* = K(X_*, X_*) - K(X_*, X)[K(X, X) + \\sigma^2_n I]^{-1}K(X, X_*)$$\n",
    "\n",
    "Here, $K$ is the RBF kernel, $X$ are the training inputs, $y$ are the training targets, $X_*$ are the test inputs, and $\\sigma^2_n$ is the noise variance.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Hessian Spectrum\n",
    "Compute the eigenspectrum of the Hessian of a pretrained neural network. You can download weights of image classifiers pretrained on CIFAR10. Use `cola.eigs` or `cola.algorithms.lanczsos` and the spectral KDE smoothing method from [this paper](https://arxiv.org/pdf/1901.10159.pdf) to get a smoothed spectrum estimate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Linear Regression\n",
    "Implement linear regression with a heteroscedastic noise model where $\\Phi$ is the design matrix, $\\beta$ are the parameters and $\\sigma_i$ is the measurement noise. The model is:\n",
    "\n",
    "    $$y = \\Phi \\beta + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, D)$$\n",
    "    \n",
    "    where $D$ is a diagonal matrix with $\\sigma_i^2$ on the diagonal. Add a Gaussian prior (regularization) if necessary.\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: $\\hat{\\beta}_{MLE} = (\\Phi^T D^{-1} \\Phi)^{-1} \\Phi^T D^{-1} y$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement pagerank to find the most influential pages of Wikipedia.\n",
    " From the transition matrix on the [Linked- WikiText-2 dataset](https://rloganiv.github.io/linked-wikitext-2/#/), compute the largest eigenvector using `cola.eigmax`. From this eigenvector, rank the values to determine which web pages are most influential.\n",
    "\n",
    "The PageRank algorithm computes the stationary distribution of a Markov chain. Given a transition matrix $P$, the PageRank vector $r$ is the eigenvector corresponding to the largest eigenvalue (which should be 1 for a stochastic matrix).\n",
    "\n",
    "The transition matrix $P$ is defined as:\n",
    "\n",
    "$$P = (1-\\alpha)W + \\alpha \\mathbf{1}\\mathbf{1}^T$$\n",
    "\n",
    "where $W$ is the adjacency matrix normalized by the degree, $\\alpha$ is the damping factor (usually set to 0.15), and $\\mathbf{1}$ is a vector of ones.\n",
    "\n",
    "The adjacency matrix $A_{ij}$ is 1 if there is a link from page $i$ to page $j$ (not the other way around). The degree-normalized adjacency matrix $W$ is obtained by dividing each row of $A$ by its sum.\n",
    "\n",
    "The PageRank vector $r$ can be found by solving the eigenproblem:\n",
    "\n",
    "$$P^T r = r$$\n",
    "\n",
    "The entries of $r$ give the PageRank scores of the pages. The pages can then be ranked by these scores to find the most influential ones.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Make a pull request to CoLA.\n",
    " e.g., improvement to the documentation, new commonly used linear operator (e.g., Fisher information matrix, banded matrix, FFT matrix), bug fix. If your code for one of the above exercises is particularly clean, consider adding markdown text explaining the steps and let's add it to the CoLA documentation under examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
